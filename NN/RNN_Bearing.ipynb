{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1)    # reproducible\n",
    "N_Input = 100\n",
    "N_Hidden = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data load\n",
    "mat1 = sio.loadmat('Bearing/N_0.mat')\n",
    "data1 = mat1['X097_DE_time']\n",
    "mat2 = sio.loadmat('Bearing/IR007_0.mat')\n",
    "data2 = mat2['X105_DE_time']\n",
    "\n",
    "Normal = data1[:50000].reshape(100,int(500/N_Input),N_Input) #100 samples for normal category, each sample contains 500 points\n",
    "Fault = data2[:50000].reshape(100,int(500/N_Input),N_Input) #100*5*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training and test data\n",
    "Normal_tensor=torch.from_numpy(Normal) # convert to torch tensor\n",
    "Fault_tensor=torch.from_numpy(Fault)\n",
    "\n",
    "#training\n",
    "Train_Data=torch.cat((Normal_tensor[0:70,:,:],Fault_tensor[:70,:,:])).type(torch.FloatTensor) #put normal and fault data together (140, 10,50)\n",
    "Train_Target=torch.cat((torch.zeros(70,1),torch.ones(70,1)),0).type(torch.LongTensor).squeeze() #squeeze: (140,1) ->(140,)\n",
    "\n",
    "#test\n",
    "Test_Data=torch.cat((Normal_tensor[70:,:,:],Fault_tensor[70:,:,:])).type(torch.FloatTensor)\n",
    "Test_Target=torch.cat((torch.zeros(30,1),torch.ones(30,1)),0).type(torch.LongTensor).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch\n",
    "Train_Dataset=Data.TensorDataset(Train_Data,Train_Target) #put X and Y together\n",
    "Test_Dataset=Data.TensorDataset(Test_Data,Test_Target)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=Train_Dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=True) #shuffle the order of samples to train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(100, 200, num_layers=3, batch_first=True)\n",
      "  (out): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "            input_size=N_Input,\n",
    "            hidden_size=N_Hidden,         # rnn hidden unit\n",
    "            num_layers=3,           # number of rnn layer\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(N_Hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        r_out, h_n = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "rnn = RNN()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.001)   # optimize all cnn parameters, sgd\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.6638 | test accuracy: 0.52\n",
      "Epoch:  2 | train loss: 0.0644 | test accuracy: 0.57\n",
      "Epoch:  4 | train loss: 0.0479 | test accuracy: 0.57\n",
      "Epoch:  6 | train loss: 0.1445 | test accuracy: 0.60\n",
      "Epoch:  8 | train loss: 0.0142 | test accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing\n",
    "EPOCH = 50\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):   # gives batch data, normalize x when iterate train_loader\n",
    "        output = rnn(b_x)            # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        test_output = rnn(Test_Data) # 60*2\n",
    "        pred_y = torch.max(test_output, 1)[1].data.squeeze() #60*2 ->60*1 ->(60,)\n",
    "        accuracy = (pred_y == Test_Target).sum().item() / float(Test_Target.size(0))\n",
    "        print('Epoch: ', epoch, '| train loss: %.4f' % loss.data, '| test accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn(b_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
