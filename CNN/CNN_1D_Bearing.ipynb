{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data load\n",
    "mat1 = sio.loadmat('Bearing/N_0.mat')\n",
    "data1 = mat1['X097_DE_time']\n",
    "mat2 = sio.loadmat('Bearing/IR007_0.mat')\n",
    "data2 = mat2['X105_DE_time']\n",
    "mat3 = sio.loadmat('Bearing/OR007@6_0.mat')\n",
    "data3 = mat3['X130_DE_time']\n",
    "mat4 = sio.loadmat('Bearing/B007_0.mat')\n",
    "data4 = mat4['X118_DE_time']\n",
    "\n",
    "Normal = data1[:50000].reshape(100,500) #for individual category, create 100 samples,individual sample contains 500 data points\n",
    "Fault1 = data2[:50000].reshape(100,500)\n",
    "Fault2 = data3[:50000].reshape(100,500)\n",
    "Fault3 = data4[:50000].reshape(100,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training and test data\n",
    "Normal_tensor=torch.from_numpy(Normal)\n",
    "Fault1_tensor=torch.from_numpy(Fault1)\n",
    "Fault2_tensor=torch.from_numpy(Fault2)\n",
    "Fault3_tensor=torch.from_numpy(Fault3)\n",
    "Train_Data=torch.cat((Normal_tensor[0:70],Fault1_tensor[:70],Fault2_tensor[:70],Fault3_tensor[:70])).type(torch.FloatTensor)\n",
    "Train_Data=torch.unsqueeze(Train_Data,1) #unsqueeze convert data from (280,500) to (280,1,500), add additional dimension to match the requirment of data structure in CNN\n",
    "Test_Data=torch.cat((Normal_tensor[70:],Fault1_tensor[70:],Fault2_tensor[70:],Fault3_tensor[70:])).type(torch.FloatTensor)\n",
    "Test_Data=torch.unsqueeze(Test_Data,1)\n",
    "Train_Target=torch.cat((torch.zeros(70,1),torch.ones(70,1),2*torch.ones(70,1),3*torch.ones(70,1)),0).type(torch.LongTensor).squeeze() #squeeze data to create one-dimensional label\n",
    "Test_Target=torch.cat((torch.zeros(30,1),torch.ones(30,1), 2*torch.ones(30,1),3*torch.ones(30,1)),0).type(torch.LongTensor).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch\n",
    "Train_Dataset=Data.TensorDataset(Train_Data,Train_Target)\n",
    "Test_Dataset=Data.TensorDataset(Test_Data,Test_Target)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=Train_Dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(1, 16, kernel_size=(5,), stride=(3,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(16, 32, kernel_size=(5,), stride=(2,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=608, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define 1-D CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (10,1,500) second dimension corresponds to the number of feature maps, third dimension corresponds to the lenght/size of an feature map\n",
    "            nn.Conv1d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=3,                   \n",
    "                padding=0,                 # (500-5)/3+1 =166\n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool1d(kernel_size=3, stride = 2),    # (166-3)/2+1 = 82.5 -> 82\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (10, 16, 82)\n",
    "            nn.Conv1d(16, 32, 5, 2, 0),     # (82-5)/2+1 = 39.5->39\n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool1d(kernel_size=2, stride = 2)  # (39-2)/2+1 =19.5 -> 19 output shape (10, 32, 19)\n",
    "        )\n",
    "        self.out = nn.Linear(608, 4)   # 32*19 = 608 fully connected layer, output 10 classes\n",
    "        #self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 19)\n",
    "        x = self.out(x)\n",
    "        #output = self.softmax(x)\n",
    "        return output, x    # return x for visualization\n",
    "\n",
    "cnn = CNN()\n",
    "print (cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.01)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.0398 | test accuracy: 0.99\n",
      "Epoch:  2 | train loss: 0.0007 | test accuracy: 1.00\n",
      "Epoch:  4 | train loss: 0.0004 | test accuracy: 1.00\n",
      "Epoch:  6 | train loss: 0.0002 | test accuracy: 1.00\n",
      "Epoch:  8 | train loss: 0.0001 | test accuracy: 1.00\n",
      "Epoch:  10 | train loss: 0.0002 | test accuracy: 1.00\n",
      "Epoch:  12 | train loss: 0.0001 | test accuracy: 1.00\n",
      "Epoch:  14 | train loss: 0.0002 | test accuracy: 1.00\n",
      "Epoch:  16 | train loss: 0.0000 | test accuracy: 1.00\n",
      "Epoch:  18 | train loss: 0.0001 | test accuracy: 1.00\n",
      "Epoch:  20 | train loss: 0.0001 | test accuracy: 1.00\n",
      "Epoch:  22 | train loss: 0.0001 | test accuracy: 1.00\n",
      "Epoch:  24 | train loss: 0.0001 | test accuracy: 1.00\n",
      "Epoch:  26 | train loss: 0.0000 | test accuracy: 1.00\n",
      "Epoch:  28 | train loss: 0.0001 | test accuracy: 1.00\n",
      "Epoch:  30 | train loss: 0.0000 | test accuracy: 1.00\n",
      "Epoch:  32 | train loss: 0.0001 | test accuracy: 1.00\n",
      "Epoch:  34 | train loss: 0.0000 | test accuracy: 1.00\n",
      "Epoch:  36 | train loss: 0.0000 | test accuracy: 1.00\n",
      "Epoch:  38 | train loss: 0.0000 | test accuracy: 1.00\n",
      "Epoch:  40 | train loss: 0.0001 | test accuracy: 1.00\n",
      "Epoch:  42 | train loss: 0.0000 | test accuracy: 1.00\n",
      "Epoch:  44 | train loss: 0.0000 | test accuracy: 1.00\n",
      "Epoch:  46 | train loss: 0.0000 | test accuracy: 1.00\n",
      "Epoch:  48 | train loss: 0.0000 | test accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing\n",
    "EPOCH = 50\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):   # gives batch data, normalize x when iterate train_loader\n",
    "\n",
    "        output = cnn(b_x)[1]               # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "\n",
    "        \n",
    "    if epoch % 2 == 0:\n",
    "        test_output, last_layer = cnn(Test_Data) #test_output: 60*2\n",
    "        pred_y = torch.max(last_layer, 1)[1].data.squeeze() #squeeze(): 60*1->(60,)\n",
    "        accuracy = (pred_y == Test_Target).sum().item() / float(Test_Target.size(0))\n",
    "        print('Epoch: ', epoch, '| train loss: %.4f' % loss.data, '| test accuracy: %.2f' % accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-181.3687,   33.8172,   48.1283,  -64.4762],\n",
       "        [  -8.0180,   -3.0883,  -23.6354,    7.0944],\n",
       "        [ -49.4283,    4.7052,   -8.2944,   -8.0258],\n",
       "        [ -56.7409,    5.0680,   -5.0226,  -11.7922],\n",
       "        [ -46.6547,    3.5279,  -10.9500,   -7.1388],\n",
       "        [-190.2363,   33.9392,   51.2618,  -54.0032],\n",
       "        [  18.1522,   -8.3522,  -30.2409,    6.9355],\n",
       "        [ -53.8587,    6.4425,   -6.0774,   -9.7510],\n",
       "        [-164.2679,   28.0877,   44.3358,  -53.4263],\n",
       "        [ -52.7827,    5.2975,   -6.0121,  -10.6392]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "2*torch.ones(100,1).type(torch.LongTensor).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
